{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>liked_user_id</th>\n",
       "      <th>like_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462863</td>\n",
       "      <td>790124</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 00:00:05.512765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  liked_user_id  like_type                   timestamp\n",
       "0   462863         790124          0  2023-01-01 00:00:05.512765"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic, NMF, KNNWithMeans, BaselineOnly\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse, mae\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('assignment/activity.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surprise library expects data in acertain schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462863</td>\n",
       "      <td>790124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>717799</td>\n",
       "      <td>502110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288738</td>\n",
       "      <td>951824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106589</td>\n",
       "      <td>953301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338182</td>\n",
       "      <td>970712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0   462863   790124       0\n",
       "1   717799   502110       1\n",
       "2   288738   951824       0\n",
       "3   106589   953301       0\n",
       "4   338182   970712       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'liked_user_id': 'item_id', 'like_type': 'rating'})\n",
    "df.drop(columns=['timestamp'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPARSITY ANALYSIS\n",
      "Matrix sparsity: 93.07%\n",
      "Density: 6.9337%\n",
      "\n",
      "RATING DISTRIBUTION\n",
      "rating\n",
      "0    1014887\n",
      "1     425598\n",
      "2       8312\n",
      "Name: count, dtype: int64\n",
      "Number of unique rating values: 3\n",
      "⚠️  Limited rating scale - Consider ordinal approaches\n",
      "\n",
      "USER/ITEM RATING PATTERNS\n",
      "Users with only 1 rating: 218\n",
      "Items with only 1 rating: 0\n",
      "Median ratings per user: 180.0\n",
      "Median ratings per item: 290.0\n",
      "Cold start users: 5.2%\n",
      "Cold start items: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# === SPARSITY ANALYSIS ===\n",
    "print(\"\\nSPARSITY ANALYSIS\")\n",
    "total_possible = df['user_id'].nunique() * df['item_id'].nunique()\n",
    "sparsity = (1 - len(df) / total_possible) * 100\n",
    "print(f\"Matrix sparsity: {sparsity:.2f}%\")\n",
    "print(f\"Density: {(100-sparsity):.4f}%\")\n",
    "\n",
    "if sparsity > 99.5:\n",
    "    print(\"⚠️  EXTREMELY SPARSE DATA - Major issue!\")\n",
    "elif sparsity > 95:\n",
    "    print(\"⚠️  Very sparse data - This hurts CF performance\")\n",
    "\n",
    "# === RATING DISTRIBUTION ===\n",
    "print(\"\\nRATING DISTRIBUTION\")\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "print(rating_counts)\n",
    "\n",
    "unique_ratings = df['rating'].nunique()\n",
    "print(f\"Number of unique rating values: {unique_ratings}\")\n",
    "\n",
    "if unique_ratings == 2:\n",
    "    print(\"⚠️  BINARY DATA DETECTED - Consider classification approach!\")\n",
    "elif unique_ratings < 10:\n",
    "    print(\"⚠️  Limited rating scale - Consider ordinal approaches\")\n",
    "\n",
    "# === USER/ITEM RATING PATTERNS ===\n",
    "print(\"\\nUSER/ITEM RATING PATTERNS\")\n",
    "user_rating_counts = df['user_id'].value_counts()\n",
    "item_rating_counts = df['item_id'].value_counts()\n",
    "\n",
    "print(f\"Users with only 1 rating: {(user_rating_counts == 1).sum()}\")\n",
    "print(f\"Items with only 1 rating: {(item_rating_counts == 1).sum()}\")\n",
    "print(f\"Median ratings per user: {user_rating_counts.median()}\")\n",
    "print(f\"Median ratings per item: {item_rating_counts.median()}\")\n",
    "\n",
    "cold_users = (user_rating_counts == 1).sum() / len(user_rating_counts) * 100\n",
    "cold_items = (item_rating_counts == 1).sum() / len(item_rating_counts) * 100\n",
    "\n",
    "print(f\"Cold start users: {cold_users:.1f}%\")\n",
    "print(f\"Cold start items: {cold_items:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    1014887\n",
       "1     425598\n",
       "2       8312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the provided data, we can consider three main\n",
    "  strategies, each with its own strengths and weaknesses.\n",
    "\n",
    "  1. Popularity-Based Recommender\n",
    "\n",
    "\n",
    "  This is the most straightforward approach. The core idea is to recommend the users who are most popular across the entire platform,\n",
    "  regardless of who the target user is.\n",
    "\n",
    "\n",
    "   * How it works:\n",
    "       1. Calculate a \"popularity score\" for every user. This score would be the total number of positive interactions (like_type 1 for\n",
    "          \"like\" and 2 for \"match\") they have received.\n",
    "       2. To generate recommendations for a specific user_id, you would take the list of all users, rank them by this popularity score in\n",
    "          descending order.\n",
    "       3. Finally, you would filter out any users the target user has already interacted with (liked, disliked, or matched) and return the\n",
    "          top k users from the ranked list.\n",
    "   * Pros:\n",
    "       * Simple & Fast: Easy to implement and computationally inexpensive.\n",
    "       * Good Baseline: Provides a solid starting point and is effective at recommending users who are generally considered attractive on\n",
    "         the platform.\n",
    "       * Solves Cold Start: It can generate recommendations for any user, even brand new ones with no interaction history.\n",
    "   * Cons:\n",
    "       * Not Personalized: Every user receives recommendations from the same pool of popular users. It doesn't adapt to individual\n",
    "         preferences.\n",
    "       * Popularity Bias: It can create a \"rich get richer\" effect, where popular users become even more visible, and less popular users are\n",
    "         never discovered.\n",
    "\n",
    "  2. Content-Based Filtering\n",
    "\n",
    "  This approach uses the attributes of the users to recommend others with similar characteristics to those the target user has liked in the\n",
    "  past.\n",
    "\n",
    "\n",
    "   * How it works:\n",
    "       1. Create User Profiles: For each user, create a profile vector based on their attributes in users.csv (e.g., gender, age, city, and\n",
    "          even vectorized text from about_me using techniques like TF-IDF).\n",
    "       2. Build Target User Profile: Analyze the profiles of users that the target user has positively interacted with (liked/matched).\n",
    "          Combine these profiles to create an \"ideal\" profile that represents the target user's preferences.\n",
    "       3. Find Similar Users: Calculate the similarity (e.g., using cosine similarity) between the target user's ideal profile and the\n",
    "          profiles of all other candidate users.\n",
    "       4. Recommend the top k most similar users.\n",
    "   * Pros:\n",
    "       * Highly Personalized: Recommendations are tailored to a user's specific tastes.\n",
    "       * Explainable: You can easily explain why a recommendation was made (e.g., \"Because you liked other users from London who are in\n",
    "         their 30s\").\n",
    "       * No Cold Start for Items: It can recommend new users as long as they have a complete profile.\n",
    "   * Cons:\n",
    "       * User Cold Start: It cannot generate recommendations for new users who haven't interacted with anyone yet.\n",
    "       * Filter Bubble: It may over-specialize and only recommend users who are very similar to past choices, limiting discovery of new\n",
    "         types of profiles.\n",
    "       * Requires Feature Engineering: The quality of recommendations heavily depends on how well you represent the user profiles from the\n",
    "         available data.\n",
    "\n",
    "  3. Collaborative Filtering\n",
    "\n",
    "  This method makes recommendations based on the interactions of other users. The underlying assumption is that if two users have liked\n",
    "  similar people in the past, they are likely to like similar people in the future.\n",
    "\n",
    "\n",
    "   * How it works:\n",
    "       1. Build a User-Interaction Matrix: Create a matrix where rows are users and columns are the users they've interacted with. The values\n",
    "          would be the like_type.\n",
    "       2. Find Similar Users: Using this matrix, find users who are \"similar\" to the target user by finding users who have liked/disliked the\n",
    "          same set of people.\n",
    "       3. Generate Recommendations: Recommend users that these similar users have liked, but which the target user has not yet seen.\n",
    "       * Advanced methods like Matrix Factorization (SVD)** can be used to discover latent (hidden) features in the interaction data for more\n",
    "         powerful predictions.\n",
    "   * Pros:\n",
    "       * Finds Surprising Connections: It can uncover non-obvious recommendations that content-based filtering would miss, as it's not limited\n",
    "         by user attributes.\n",
    "       * No Feature Engineering: It learns directly from user behavior, so you don't need to manually create user profiles.\n",
    "   * Cons:\n",
    "       * User/Item Cold Start: It struggles with both new users (no interaction history) and new users who have received no interactions.\n",
    "       * Data Sparsity: If the platform is large and users have only interacted with a tiny fraction of other users, it can be difficult to\n",
    "         find meaningful overlaps and the quality of recommendations suffers.\n",
    "       * Computationally Expensive: Can be slow and memory-intensive, especially with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0,2))\n",
    "\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE MODELS ===\n",
      "Estimating biases using als...\n",
      "GlobalMean: RMSE=0.3736, MAE=0.2646\n",
      "SVD_Default: RMSE=0.3758, MAE=0.2642\n",
      "NMF_Default: RMSE=0.3778, MAE=0.2502\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN_Basic: RMSE=0.3771, MAE=0.2603\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN_WithMeans: RMSE=0.3777, MAE=0.2643\n",
      "\n",
      "=== HYPERPARAMETER TUNING ===\n",
      "Tuning SVD...\n",
      "Best SVD RMSE: 0.3745\n",
      "Best SVD params: {'n_factors': 50, 'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.05}\n",
      "\n",
      "Tuning NMF...\n",
      "Best NMF RMSE: 0.3783\n",
      "Best NMF params: {'n_factors': 50, 'n_epochs': 20, 'reg_pu': 0.06, 'reg_qi': 0.06}\n",
      "\n",
      "Tuning KNN...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/Documents/codes/inner_circle/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Best KNN RMSE: 0.3759\n",
      "Best KNN params: {'k': 50, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Best_SVD: RMSE=0.3738, MAE=0.2664\n",
      "Best_NMF: RMSE=0.3775, MAE=0.2498\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best_KNN: RMSE=0.3751, MAE=0.2632\n",
      "\n",
      "Best overall model: Best_SVD\n"
     ]
    }
   ],
   "source": [
    "def benchmark_collaborative_filtering(data=data):\n",
    "    \"\"\"\n",
    "    Comprehensive approach to improve collaborative filtering performance\n",
    "    \"\"\"\n",
    "\n",
    "    # === 1. BASELINE COMPARISON ===\n",
    "    print(\"=== BASELINE MODELS ===\")\n",
    "    \n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Simple baselines\n",
    "    baseline_models = {\n",
    "        'GlobalMean': BaselineOnly(bsl_options={'method': 'als'}),\n",
    "        'SVD_Default': SVD(),\n",
    "        'NMF_Default': NMF(),\n",
    "        'KNN_Basic': KNNBasic(),\n",
    "        'KNN_WithMeans': KNNWithMeans()\n",
    "    }\n",
    "    \n",
    "    baseline_results = {}\n",
    "    for name, model in baseline_models.items():\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        rmse_score = rmse(predictions, verbose=False)\n",
    "        mae_score = mae(predictions, verbose=False)\n",
    "        baseline_results[name] = {'rmse': rmse_score, 'mae': mae_score}\n",
    "        print(f\"{name}: RMSE={rmse_score:.4f}, MAE={mae_score:.4f}\")\n",
    "    \n",
    "    # === 2. HYPERPARAMETER TUNING ===\n",
    "    print(\"\\n=== HYPERPARAMETER TUNING ===\")\n",
    "    \n",
    "    # SVD Grid Search\n",
    "    print(\"Tuning SVD...\")\n",
    "    param_grid_svd = {\n",
    "        'n_factors': [50, 100, 150],\n",
    "        'n_epochs': [20, 30, 40],\n",
    "        'lr_all': [0.002, 0.005, 0.01],\n",
    "        'reg_all': [0.02, 0.05, 0.1]\n",
    "    }\n",
    "    \n",
    "    gs_svd = GridSearchCV(SVD, param_grid_svd, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "    gs_svd.fit(data)\n",
    "    \n",
    "    best_svd = gs_svd.best_estimator['rmse']\n",
    "    print(f\"Best SVD RMSE: {gs_svd.best_score['rmse']:.4f}\")\n",
    "    print(f\"Best SVD params: {gs_svd.best_params['rmse']}\")\n",
    "    \n",
    "    # NMF Grid Search  \n",
    "    print(\"\\nTuning NMF...\")\n",
    "    param_grid_nmf = {\n",
    "        'n_factors': [50, 100, 150],\n",
    "        'n_epochs': [20, 30, 40],\n",
    "        'reg_pu': [0.06, 0.1, 0.15],\n",
    "        'reg_qi': [0.06, 0.1, 0.15]\n",
    "    }\n",
    "    \n",
    "    gs_nmf = GridSearchCV(NMF, param_grid_nmf, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "    gs_nmf.fit(data)\n",
    "    \n",
    "    best_nmf = gs_nmf.best_estimator['rmse']\n",
    "    print(f\"Best NMF RMSE: {gs_nmf.best_score['rmse']:.4f}\")\n",
    "    print(f\"Best NMF params: {gs_nmf.best_params['rmse']}\")\n",
    "    \n",
    "    # KNN Grid Search\n",
    "    print(\"\\nTuning KNN...\")\n",
    "    param_grid_knn = {\n",
    "        'k': [20, 30, 40, 50],\n",
    "        'sim_options': {\n",
    "            'name': ['pearson', 'msd'],\n",
    "            'user_based': [True, False]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    gs_knn = GridSearchCV(KNNWithMeans, param_grid_knn, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "    gs_knn.fit(data)\n",
    "    \n",
    "    best_knn = gs_knn.best_estimator['rmse']\n",
    "    print(f\"Best KNN RMSE: {gs_knn.best_score['rmse']:.4f}\")\n",
    "    print(f\"Best KNN params: {gs_knn.best_params['rmse']}\")\n",
    "    \n",
    "    # === 3. FINAL COMPARISON ===\n",
    "    print(\"\\n=== FINAL COMPARISON ===\")\n",
    "    \n",
    "    best_models = {\n",
    "        'Best_SVD': best_svd,\n",
    "        'Best_NMF': best_nmf, \n",
    "        'Best_KNN': best_knn\n",
    "    }\n",
    "    \n",
    "    final_results = {}\n",
    "    for name, model in best_models.items():\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        rmse_score = rmse(predictions, verbose=False)\n",
    "        mae_score = mae(predictions, verbose=False)\n",
    "        final_results[name] = {'rmse': rmse_score, 'mae': mae_score, 'model': model}\n",
    "        print(f\"{name}: RMSE={rmse_score:.4f}, MAE={mae_score:.4f}\")\n",
    "    \n",
    "    # Return best performing model\n",
    "    best_model_name = min(final_results.keys(), key=lambda x: final_results[x]['rmse'])\n",
    "    print(f\"\\nBest overall model: {best_model_name}\")\n",
    "    \n",
    "    return final_results[best_model_name]['model'], final_results\n",
    "\n",
    "result = benchmark_collaborative_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1060dc0b0>,\n",
       " {'Best_SVD': {'rmse': 0.37384830026043453,\n",
       "   'mae': 0.2663610668695889,\n",
       "   'model': <surprise.prediction_algorithms.matrix_factorization.SVD at 0x1060dc0b0>},\n",
       "  'Best_NMF': {'rmse': 0.3775389658844272,\n",
       "   'mae': 0.24977965958254525,\n",
       "   'model': <surprise.prediction_algorithms.matrix_factorization.NMF at 0x11ce5ecc0>},\n",
       "  'Best_KNN': {'rmse': 0.3751176686331623,\n",
       "   'mae': 0.26323911359958424,\n",
       "   'model': <surprise.prediction_algorithms.knns.KNNWithMeans at 0x1067c21b0>}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproaches to try:\n",
    "- More aggressive filtering: Remove users/items with very few ratings\n",
    "- Remove duplicates, keeping last rating\n",
    "- Deep learning approaches (neural collaborative filtering)\n",
    "- Ensemble methods\n",
    "- Implicit feedback models (BPR, WARP)\n",
    "- Add regularization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1448797 ratings\n",
      "Cleaned: 1276645 ratings\n"
     ]
    }
   ],
   "source": [
    "# Remove users/items with very few ratings\n",
    "user_counts = df['user_id'].value_counts()\n",
    "item_counts = df['item_id'].value_counts()\n",
    "\n",
    "# More aggressive filtering\n",
    "min_ratings = 250\n",
    "valid_users = user_counts[user_counts >= min_ratings].index\n",
    "valid_items = item_counts[item_counts >= min_ratings].index\n",
    "\n",
    "df_clean = df[\n",
    "    (df['user_id'].isin(valid_users)) & \n",
    "    (df['item_id'].isin(valid_items))\n",
    "].copy()\n",
    "\n",
    "# Remove duplicates, keeping last rating\n",
    "df_clean = df_clean.drop_duplicates(['user_id', 'item_id'], keep='last')\n",
    "\n",
    "print(f\"Original: {len(df)} ratings\")\n",
    "print(f\"Cleaned: {len(df_clean)} ratings\")\n",
    "\n",
    "if len(df_clean) < len(df) * 0.5:\n",
    "    print(\"⚠️  Lost too much data in cleaning!\")\n",
    "    df_clean = df  # Revert to original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE MODELS ===\n",
      "Estimating biases using als...\n",
      "GlobalMean: RMSE=0.3736, MAE=0.2646\n",
      "SVD_Default: RMSE=0.3758, MAE=0.2642\n",
      "NMF_Default: RMSE=0.3778, MAE=0.2502\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN_Basic: RMSE=0.3771, MAE=0.2603\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN_WithMeans: RMSE=0.3777, MAE=0.2643\n",
      "\n",
      "=== HYPERPARAMETER TUNING ===\n",
      "Tuning SVD...\n",
      "Best SVD RMSE: 0.3745\n",
      "Best SVD params: {'n_factors': 50, 'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.05}\n",
      "\n",
      "Tuning NMF...\n",
      "Best NMF RMSE: 0.3783\n",
      "Best NMF params: {'n_factors': 50, 'n_epochs': 20, 'reg_pu': 0.06, 'reg_qi': 0.06}\n",
      "\n",
      "Tuning KNN...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Best KNN RMSE: 0.3759\n",
      "Best KNN params: {'k': 50, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Best_SVD: RMSE=0.3738, MAE=0.2663\n",
      "Best_NMF: RMSE=0.3775, MAE=0.2498\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best_KNN: RMSE=0.3751, MAE=0.2632\n",
      "\n",
      "Best overall model: Best_SVD\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0,2))\n",
    "\n",
    "data = Dataset.load_from_df(df_clean[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "results = benchmark_collaborative_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<surprise.prediction_algorithms.matrix_factorization.SVD at 0x322c64680>,\n",
       " {'Best_SVD': {'rmse': 0.3738270261925852,\n",
       "   'mae': 0.2663290632999272,\n",
       "   'model': <surprise.prediction_algorithms.matrix_factorization.SVD at 0x322c64680>},\n",
       "  'Best_NMF': {'rmse': 0.37753657543021096,\n",
       "   'mae': 0.24978083922512823,\n",
       "   'model': <surprise.prediction_algorithms.matrix_factorization.NMF at 0x11daab890>},\n",
       "  'Best_KNN': {'rmse': 0.3751176686331623,\n",
       "   'mae': 0.26323911359958424,\n",
       "   'model': <surprise.prediction_algorithms.knns.KNNWithMeans at 0x303e82db0>}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize with your dataframe\\nadvanced_cf = AdvancedCollaborativeFiltering(df, rating_scale=(0, 1))\\n\\n# Run all techniques\\nresults = advanced_cf.run_all_techniques()\\n\\n# Or run individual techniques\\n# ncf_model, ncf_rmse, ncf_mae = advanced_cf.neural_collaborative_filtering()\\n# ensemble_pred, ens_rmse, ens_mae = advanced_cf.ensemble_methods()\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from surprise import Dataset as SurpriseDataset, Reader, SVD, NMF, KNNWithMeans\n",
    "from surprise.model_selection import train_test_split as surprise_split\n",
    "from surprise.accuracy import rmse, mae\n",
    "\n",
    "class NCFDataset(Dataset):\n",
    "    \"\"\"Custom dataset for Neural Collaborative Filtering\"\"\"\n",
    "    def __init__(self, users, items, ratings):\n",
    "        self.users = torch.LongTensor(users)\n",
    "        self.items = torch.LongTensor(items)\n",
    "        self.ratings = torch.FloatTensor(ratings)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "class NeuralCollaborativeFiltering(nn.Module):\n",
    "    \"\"\"Neural Collaborative Filtering model in PyTorch\"\"\"\n",
    "    def __init__(self, n_users, n_items, embedding_dim=50, hidden_units=[128, 64], \n",
    "                 dropout_rate=0.3, l2_reg=0.01):\n",
    "        super(NeuralCollaborativeFiltering, self).__init__()\n",
    "        \n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        \n",
    "        # Apply L2 regularization to embeddings\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        \n",
    "        # Hidden layers\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2  # Concatenated embeddings\n",
    "        \n",
    "        for hidden_dim in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        layers.append(nn.Sigmoid())  # For 0-1 rating range\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        # L2 regularization parameter\n",
    "        self.l2_reg = l2_reg\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        # Get embeddings\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        concat_emb = torch.cat([user_emb, item_emb], dim=1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        output = self.mlp(concat_emb)\n",
    "        \n",
    "        return output.squeeze()\n",
    "    \n",
    "    def get_l2_loss(self):\n",
    "        \"\"\"Calculate L2 regularization loss\"\"\"\n",
    "        l2_loss = 0\n",
    "        for param in self.parameters():\n",
    "            l2_loss += torch.norm(param) ** 2\n",
    "        return self.l2_reg * l2_loss\n",
    "\n",
    "class AdvancedCollaborativeFiltering:\n",
    "    \"\"\"\n",
    "    Advanced collaborative filtering techniques for challenging datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, rating_scale=(0, 2)):\n",
    "        self.df = df.copy()\n",
    "        self.rating_scale = rating_scale\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.item_encoder = LabelEncoder()\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.prepare_data()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare data for advanced techniques\"\"\"\n",
    "        # Remove duplicates\n",
    "        self.df = self.df.drop_duplicates(['user_id', 'item_id'], keep='last')\n",
    "        \n",
    "        # Encode users and items to continuous integers\n",
    "        self.df['user_encoded'] = self.user_encoder.fit_transform(self.df['user_id'])\n",
    "        self.df['item_encoded'] = self.item_encoder.fit_transform(self.df['item_id'])\n",
    "        \n",
    "        self.n_users = self.df['user_encoded'].nunique()\n",
    "        self.n_items = self.df['item_encoded'].nunique()\n",
    "        \n",
    "        print(f\"Prepared data: {len(self.df)} ratings, {self.n_users} users, {self.n_items} items\")\n",
    "    \n",
    "    def neural_collaborative_filtering(self, embedding_dim=50, hidden_units=[128, 64], \n",
    "                                     dropout_rate=0.3, l2_reg=0.01, epochs=50, \n",
    "                                     batch_size=256, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Neural Collaborative Filtering (NCF) implementation with PyTorch\n",
    "        \"\"\"\n",
    "        print(\"\\n=== NEURAL COLLABORATIVE FILTERING (PyTorch) ===\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df, test_df = train_test_split(self.df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = NCFDataset(\n",
    "            train_df['user_encoded'].values,\n",
    "            train_df['item_encoded'].values,\n",
    "            train_df['rating'].values\n",
    "        )\n",
    "        \n",
    "        test_dataset = NCFDataset(\n",
    "            test_df['user_encoded'].values,\n",
    "            test_df['item_encoded'].values,\n",
    "            test_df['rating'].values\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = NeuralCollaborativeFiltering(\n",
    "            n_users=self.n_users,\n",
    "            n_items=self.n_items,\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_units=hidden_units,\n",
    "            dropout_rate=dropout_rate,\n",
    "            l2_reg=l2_reg\n",
    "        ).to(self.device)\n",
    "        \n",
    "        print(f\"NCF Model Architecture:\")\n",
    "        print(model)\n",
    "        print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch_users, batch_items, batch_ratings in train_loader:\n",
    "                batch_users = batch_users.to(self.device)\n",
    "                batch_items = batch_items.to(self.device)\n",
    "                batch_ratings = batch_ratings.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                predictions = model(batch_users, batch_items)\n",
    "                \n",
    "                # Calculate loss with L2 regularization\n",
    "                mse_loss = criterion(predictions, batch_ratings)\n",
    "                l2_loss = model.get_l2_loss()\n",
    "                total_loss = mse_loss + l2_loss\n",
    "                \n",
    "                # Backward pass\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += total_loss.item()\n",
    "            \n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            \n",
    "            # Print progress every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_users, batch_items, batch_ratings in test_loader:\n",
    "                batch_users = batch_users.to(self.device)\n",
    "                batch_items = batch_items.to(self.device)\n",
    "                batch_ratings = batch_ratings.to(self.device)\n",
    "                \n",
    "                predictions = model(batch_users, batch_items)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_targets.extend(batch_ratings.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_targets = np.array(all_targets)\n",
    "        \n",
    "        test_rmse = np.sqrt(np.mean((all_targets - all_predictions)**2))\n",
    "        test_mae = np.mean(np.abs(all_targets - all_predictions))\n",
    "        \n",
    "        print(f\"NCF Results - RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}\")\n",
    "        \n",
    "        return model, test_rmse, test_mae\n",
    "    \n",
    "    def ensemble_methods(self):\n",
    "        \"\"\"\n",
    "        Ensemble of multiple collaborative filtering models\n",
    "        \"\"\"\n",
    "        print(\"\\n=== ENSEMBLE METHODS ===\")\n",
    "        \n",
    "        # Prepare Surprise data\n",
    "        reader = Reader(rating_scale=self.rating_scale)\n",
    "        data = SurpriseDataset.load_from_df(self.df[['user_id', 'item_id', 'rating']], reader)\n",
    "        trainset, testset = surprise_split(data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Individual models with different hyperparameters\n",
    "        models = {\n",
    "            'SVD1': SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02),\n",
    "            'SVD2': SVD(n_factors=100, n_epochs=30, lr_all=0.01, reg_all=0.05),\n",
    "            'SVD3': SVD(n_factors=150, n_epochs=40, lr_all=0.007, reg_all=0.03),\n",
    "            'NMF1': NMF(n_factors=50, n_epochs=30, reg_pu=0.06, reg_qi=0.06),\n",
    "            'NMF2': NMF(n_factors=100, n_epochs=40, reg_pu=0.1, reg_qi=0.1),\n",
    "            'KNN': KNNWithMeans(k=40, sim_options={'name': 'pearson', 'user_based': False})\n",
    "        }\n",
    "        \n",
    "        # Train all models\n",
    "        trained_models = {}\n",
    "        individual_predictions = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(trainset)\n",
    "            predictions = model.test(testset)\n",
    "            \n",
    "            # Calculate individual performance\n",
    "            rmse_score = rmse(predictions, verbose=False)\n",
    "            mae_score = mae(predictions, verbose=False)\n",
    "            print(f\"{name}: RMSE={rmse_score:.4f}, MAE={mae_score:.4f}\")\n",
    "            \n",
    "            trained_models[name] = model\n",
    "            individual_predictions[name] = predictions\n",
    "        \n",
    "        # Create ensemble predictions\n",
    "        print(\"\\nCreating ensemble...\")\n",
    "        ensemble_predictions = []\n",
    "        \n",
    "        for i in range(len(testset)):\n",
    "            uid = testset[i][0]\n",
    "            iid = testset[i][1]\n",
    "            true_rating = testset[i][2]\n",
    "            \n",
    "            # Get predictions from all models\n",
    "            model_preds = []\n",
    "            for name, model in trained_models.items():\n",
    "                pred = model.predict(uid, iid)\n",
    "                model_preds.append(pred.est)\n",
    "            \n",
    "            # Simple average ensemble\n",
    "            ensemble_est = np.mean(model_preds)\n",
    "            \n",
    "            # Weighted ensemble (give more weight to better performing models)\n",
    "            # You can adjust weights based on individual model performance\n",
    "            weights = [0.2, 0.2, 0.15, 0.15, 0.15, 0.15]  # Adjust as needed\n",
    "            weighted_ensemble_est = np.average(model_preds, weights=weights)\n",
    "            \n",
    "            from surprise import Prediction\n",
    "            ensemble_predictions.append(Prediction(uid, iid, true_rating, weighted_ensemble_est, {}))\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        ensemble_rmse = rmse(ensemble_predictions, verbose=False)\n",
    "        ensemble_mae = mae(ensemble_predictions, verbose=False)\n",
    "        \n",
    "        print(f\"\\nEnsemble Results - RMSE: {ensemble_rmse:.4f}, MAE: {ensemble_mae:.4f}\")\n",
    "        \n",
    "        return ensemble_predictions, ensemble_rmse, ensemble_mae\n",
    "    \n",
    "    def implicit_feedback_approach(self):\n",
    "        \"\"\"\n",
    "        Implicit feedback approach using matrix factorization\n",
    "        \"\"\"\n",
    "        print(\"\\n=== IMPLICIT FEEDBACK APPROACH ===\")\n",
    "        \n",
    "        # Create user-item interaction matrix\n",
    "        interaction_matrix = self.df.pivot_table(\n",
    "            index='user_encoded', \n",
    "            columns='item_encoded', \n",
    "            values='rating', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        print(f\"Interaction matrix shape: {interaction_matrix.shape}\")\n",
    "        print(f\"Sparsity: {(interaction_matrix == 0).sum().sum() / interaction_matrix.size * 100:.2f}%\")\n",
    "        \n",
    "        # Simple implicit feedback with confidence weighting\n",
    "        # Convert ratings to binary (0/1) and add confidence\n",
    "        binary_matrix = (interaction_matrix > 0).astype(int)\n",
    "        confidence_matrix = 1 + interaction_matrix * 10  # Higher rating = higher confidence\n",
    "        \n",
    "        # Use SVD with implicit feedback interpretation\n",
    "        from surprise import SVD\n",
    "        \n",
    "        # Create implicit dataset\n",
    "        implicit_data = []\n",
    "        for user_idx in range(len(binary_matrix)):\n",
    "            for item_idx in range(len(binary_matrix.columns)):\n",
    "                if binary_matrix.iloc[user_idx, item_idx] == 1:\n",
    "                    # Positive feedback\n",
    "                    confidence = confidence_matrix.iloc[user_idx, item_idx]\n",
    "                    # Add multiple entries based on confidence\n",
    "                    for _ in range(int(confidence)):\n",
    "                        implicit_data.append((user_idx, item_idx, 1))\n",
    "                else:\n",
    "                    # Negative feedback (sample some)\n",
    "                    if np.random.random() < 0.1:  # Sample 10% of negative feedback\n",
    "                        implicit_data.append((user_idx, item_idx, 0))\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        implicit_df = pd.DataFrame(implicit_data, columns=['user_id', 'item_id', 'rating'])\n",
    "        \n",
    "        # Train implicit model\n",
    "        reader = Reader(rating_scale=(0, 1))\n",
    "        implicit_surprise_data = SurpriseDataset.load_from_df(implicit_df, reader)\n",
    "        trainset, testset = surprise_split(implicit_surprise_data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        implicit_model = SVD(n_factors=100, n_epochs=30, lr_all=0.01, reg_all=0.02)\n",
    "        implicit_model.fit(trainset)\n",
    "        \n",
    "        predictions = implicit_model.test(testset)\n",
    "        implicit_rmse = rmse(predictions, verbose=False)\n",
    "        implicit_mae = mae(predictions, verbose=False)\n",
    "        \n",
    "        print(f\"Implicit Feedback Results - RMSE: {implicit_rmse:.4f}, MAE: {implicit_mae:.4f}\")\n",
    "        \n",
    "        return implicit_model, implicit_rmse, implicit_mae\n",
    "    \n",
    "    def advanced_regularization_svd(self):\n",
    "        \"\"\"\n",
    "        SVD with advanced regularization techniques\n",
    "        \"\"\"\n",
    "        print(\"\\n=== ADVANCED REGULARIZATION SVD ===\")\n",
    "        \n",
    "        reader = Reader(rating_scale=self.rating_scale)\n",
    "        data = SurpriseDataset.load_from_df(self.df[['user_id', 'item_id', 'rating']], reader)\n",
    "        trainset, testset = surprise_split(data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Try different regularization strategies\n",
    "        reg_models = {\n",
    "            'High_Reg': SVD(n_factors=100, n_epochs=30, lr_all=0.005, reg_all=0.1),\n",
    "            'Biased_Reg': SVD(n_factors=100, n_epochs=30, lr_all=0.01, reg_all=0.02, biased=True),\n",
    "            'Low_LR': SVD(n_factors=150, n_epochs=50, lr_all=0.002, reg_all=0.05),\n",
    "            'Adaptive': SVD(n_factors=100, n_epochs=30, lr_all=0.01, reg_all=0.02, biased=True)\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for name, model in reg_models.items():\n",
    "            model.fit(trainset)\n",
    "            predictions = model.test(testset)\n",
    "            rmse_score = rmse(predictions, verbose=False)\n",
    "            mae_score = mae(predictions, verbose=False)\n",
    "            results[name] = {'rmse': rmse_score, 'mae': mae_score, 'model': model}\n",
    "            print(f\"{name}: RMSE={rmse_score:.4f}, MAE={mae_score:.4f}\")\n",
    "        \n",
    "        # Return best model\n",
    "        best_model_name = min(results.keys(), key=lambda x: results[x]['rmse'])\n",
    "        print(f\"Best regularization approach: {best_model_name}\")\n",
    "        \n",
    "        return results[best_model_name]['model'], results[best_model_name]['rmse'], results[best_model_name]['mae']\n",
    "    \n",
    "    def run_all_techniques(self):\n",
    "        \"\"\"\n",
    "        Run all advanced techniques and compare results\n",
    "        \"\"\"\n",
    "        print(\"=== RUNNING ALL ADVANCED TECHNIQUES ===\")\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        # 1. Neural Collaborative Filtering (PyTorch)\n",
    "        try:\n",
    "            ncf_model, ncf_rmse, ncf_mae = self.neural_collaborative_filtering()\n",
    "            all_results['NCF_PyTorch'] = {'rmse': ncf_rmse, 'mae': ncf_mae}\n",
    "        except Exception as e:\n",
    "            print(f\"NCF failed: {e}\")\n",
    "            all_results['NCF_PyTorch'] = {'rmse': float('inf'), 'mae': float('inf')}\n",
    "        \n",
    "        # 2. Ensemble Methods\n",
    "        try:\n",
    "            _, ensemble_rmse, ensemble_mae = self.ensemble_methods()\n",
    "            all_results['Ensemble'] = {'rmse': ensemble_rmse, 'mae': ensemble_mae}\n",
    "        except Exception as e:\n",
    "            print(f\"Ensemble failed: {e}\")\n",
    "            all_results['Ensemble'] = {'rmse': float('inf'), 'mae': float('inf')}\n",
    "        \n",
    "        # 3. Implicit Feedback\n",
    "        try:\n",
    "            _, implicit_rmse, implicit_mae = self.implicit_feedback_approach()\n",
    "            all_results['Implicit'] = {'rmse': implicit_rmse, 'mae': implicit_mae}\n",
    "        except Exception as e:\n",
    "            print(f\"Implicit failed: {e}\")\n",
    "            all_results['Implicit'] = {'rmse': float('inf'), 'mae': float('inf')}\n",
    "        \n",
    "        # 4. Advanced Regularization\n",
    "        try:\n",
    "            _, reg_rmse, reg_mae = self.advanced_regularization_svd()\n",
    "            all_results['Advanced_Reg'] = {'rmse': reg_rmse, 'mae': reg_mae}\n",
    "        except Exception as e:\n",
    "            print(f\"Advanced Regularization failed: {e}\")\n",
    "            all_results['Advanced_Reg'] = {'rmse': float('inf'), 'mae': float('inf')}\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n=== FINAL COMPARISON ===\")\n",
    "        print(\"Method\\t\\tRMSE\\t\\tMAE\")\n",
    "        print(\"-\" * 40)\n",
    "        for method, results in all_results.items():\n",
    "            print(f\"{method}\\t\\t{results['rmse']:.4f}\\t\\t{results['mae']:.4f}\")\n",
    "        \n",
    "        # Best method\n",
    "        best_method = min(all_results.keys(), key=lambda x: all_results[x]['rmse'])\n",
    "        print(f\"\\nBest method: {best_method}\")\n",
    "        print(f\"Best RMSE: {all_results[best_method]['rmse']:.4f}\")\n",
    "        print(f\"Best MAE: {all_results[best_method]['mae']:.4f}\")\n",
    "        \n",
    "        return all_results\n",
    "\n",
    "# === USAGE EXAMPLE ===\n",
    "\"\"\"\n",
    "# Initialize with your dataframe\n",
    "advanced_cf = AdvancedCollaborativeFiltering(df, rating_scale=(0, 1))\n",
    "\n",
    "# Run all techniques\n",
    "results = advanced_cf.run_all_techniques()\n",
    "\n",
    "# Or run individual techniques\n",
    "# ncf_model, ncf_rmse, ncf_mae = advanced_cf.neural_collaborative_filtering()\n",
    "# ensemble_pred, ens_rmse, ens_mae = advanced_cf.ensemble_methods()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Prepared data: 1448797 ratings, 4179 users, 5000 items\n",
      "=== RUNNING ALL ADVANCED TECHNIQUES ===\n",
      "\n",
      "=== NEURAL COLLABORATIVE FILTERING (PyTorch) ===\n",
      "NCF Model Architecture:\n",
      "NeuralCollaborativeFiltering(\n",
      "  (user_embedding): Embedding(4179, 50)\n",
      "  (item_embedding): Embedding(5000, 50)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total parameters: 480199\n",
      "Epoch 10/50, Loss: 0.2290\n",
      "Epoch 20/50, Loss: 0.2290\n",
      "Epoch 30/50, Loss: 0.2290\n",
      "Epoch 40/50, Loss: 0.2290\n",
      "Epoch 50/50, Loss: 0.2290\n",
      "NCF Results - RMSE: 0.4741, MAE: 0.4398\n",
      "\n",
      "=== ENSEMBLE METHODS ===\n",
      "Training SVD1...\n",
      "SVD1: RMSE=0.3749, MAE=0.2636\n",
      "Training SVD2...\n",
      "SVD2: RMSE=0.3746, MAE=0.2667\n",
      "Training SVD3...\n",
      "SVD3: RMSE=0.3748, MAE=0.2646\n",
      "Training NMF1...\n",
      "NMF1: RMSE=0.3778, MAE=0.2502\n",
      "Training NMF2...\n",
      "NMF2: RMSE=0.3855, MAE=0.2439\n",
      "Training KNN...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN: RMSE=0.3786, MAE=0.2640\n",
      "\n",
      "Creating ensemble...\n",
      "\n",
      "Ensemble Results - RMSE: 0.3744, MAE: 0.2591\n",
      "\n",
      "=== IMPLICIT FEEDBACK APPROACH ===\n",
      "Interaction matrix shape: (4179, 5000)\n",
      "Sparsity: 97.92%\n",
      "Implicit Feedback Results - RMSE: 0.2409, MAE: 0.1563\n",
      "\n",
      "=== ADVANCED REGULARIZATION SVD ===\n",
      "High_Reg: RMSE=0.3743, MAE=0.2719\n",
      "Biased_Reg: RMSE=0.3796, MAE=0.2646\n",
      "Low_LR: RMSE=0.3739, MAE=0.2665\n",
      "Adaptive: RMSE=0.3795, MAE=0.2645\n",
      "Best regularization approach: Low_LR\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Method\t\tRMSE\t\tMAE\n",
      "----------------------------------------\n",
      "NCF_PyTorch\t\t0.4741\t\t0.4398\n",
      "Ensemble\t\t0.3744\t\t0.2591\n",
      "Implicit\t\t0.2409\t\t0.1563\n",
      "Advanced_Reg\t\t0.3739\t\t0.2665\n",
      "\n",
      "Best method: Implicit\n",
      "Best RMSE: 0.2409\n",
      "Best MAE: 0.1563\n"
     ]
    }
   ],
   "source": [
    "advanced_cf = AdvancedCollaborativeFiltering(df, rating_scale=(0, 2))\n",
    "results = advanced_cf.run_all_techniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NCF_PyTorch': {'rmse': 0.47413218, 'mae': 0.43983847},\n",
       " 'Ensemble': {'rmse': 0.3744485822597834, 'mae': 0.259090336856249},\n",
       " 'Implicit': {'rmse': 0.2409351085272274, 'mae': 0.15628666822459183},\n",
       " 'Advanced_Reg': {'rmse': 0.3739094035226511, 'mae': 0.2664917083882635}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Prepared data: 1276645 ratings, 1823 users, 4993 items\n",
      "=== RUNNING ALL ADVANCED TECHNIQUES ===\n",
      "\n",
      "=== NEURAL COLLABORATIVE FILTERING (PyTorch) ===\n",
      "NCF Model Architecture:\n",
      "NeuralCollaborativeFiltering(\n",
      "  (user_embedding): Embedding(1823, 50)\n",
      "  (item_embedding): Embedding(4993, 50)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total parameters: 362049\n",
      "Epoch 10/50, Loss: 0.2295\n",
      "Epoch 20/50, Loss: 0.2295\n",
      "Epoch 30/50, Loss: 0.2295\n",
      "Epoch 40/50, Loss: 0.2295\n",
      "Epoch 50/50, Loss: 0.2295\n",
      "NCF Results - RMSE: 0.4736, MAE: 0.4401\n",
      "\n",
      "=== ENSEMBLE METHODS ===\n",
      "Training SVD1...\n",
      "SVD1: RMSE=0.3754, MAE=0.2631\n",
      "Training SVD2...\n",
      "SVD2: RMSE=0.3751, MAE=0.2661\n",
      "Training SVD3...\n",
      "SVD3: RMSE=0.3753, MAE=0.2640\n",
      "Training NMF1...\n",
      "NMF1: RMSE=0.3785, MAE=0.2500\n",
      "Training NMF2...\n",
      "NMF2: RMSE=0.3864, MAE=0.2438\n",
      "Training KNN...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN: RMSE=0.3785, MAE=0.2632\n",
      "\n",
      "Creating ensemble...\n",
      "\n",
      "Ensemble Results - RMSE: 0.3751, MAE: 0.2586\n",
      "\n",
      "=== IMPLICIT FEEDBACK APPROACH ===\n",
      "Interaction matrix shape: (1823, 4993)\n",
      "Sparsity: 95.79%\n",
      "Implicit Feedback Results - RMSE: 0.2231, MAE: 0.1301\n",
      "\n",
      "=== ADVANCED REGULARIZATION SVD ===\n",
      "High_Reg: RMSE=0.3749, MAE=0.2715\n",
      "Biased_Reg: RMSE=0.3797, MAE=0.2640\n",
      "Low_LR: RMSE=0.3744, MAE=0.2661\n",
      "Adaptive: RMSE=0.3796, MAE=0.2637\n",
      "Best regularization approach: Low_LR\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Method\t\tRMSE\t\tMAE\n",
      "----------------------------------------\n",
      "NCF_PyTorch\t\t0.4736\t\t0.4401\n",
      "Ensemble\t\t0.3751\t\t0.2586\n",
      "Implicit\t\t0.2231\t\t0.1301\n",
      "Advanced_Reg\t\t0.3744\t\t0.2661\n",
      "\n",
      "Best method: Implicit\n",
      "Best RMSE: 0.2231\n",
      "Best MAE: 0.1301\n"
     ]
    }
   ],
   "source": [
    "advanced_cf = AdvancedCollaborativeFiltering(df_clean, rating_scale=(0, 2))\n",
    "results = advanced_cf.run_all_techniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NCF_PyTorch': {'rmse': 0.47359955, 'mae': 0.4400797},\n",
       " 'Ensemble': {'rmse': 0.37511636081441874, 'mae': 0.2586405027922102},\n",
       " 'Implicit': {'rmse': 0.22305644997804586, 'mae': 0.13013373128362954},\n",
       " 'Advanced_Reg': {'rmse': 0.3743759917590676, 'mae': 0.266138846491769}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision@10 (Quality): This tells us, \"Of the 10 users we recommended, what percentage were actually good recommendations (liked or matched)?\"\n",
    "</br>\n",
    "Recall@10 (Coverage): This answers, \"Of all the people a user would have liked, what percentage did we successfully find in our top 10 recommendations?\"\n",
    "\n",
    "   * Precision/Recall answer: \"How good are my top-k rankings?\"\n",
    "   * RMSE/MAE answer: \"How good is my model at predicting the exact rating a user would give?\"\n",
    "<br>\n",
    "\n",
    "#### MAE: Mean Absolute Error\n",
    "\n",
    "*The question it answers:* \"On average, how far off was our prediction from the user's actual rating?\"\n",
    "\n",
    "#### RMSE: Root Mean Squared Error\n",
    "\n",
    "*The question it answers:* \"How far off are our predictions, but with a special penalty for being very wrong?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic, NMF\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=1):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@k: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@k: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "def run_evaluation():\n",
    "    df = pd.read_csv('assignment/activity.csv')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Time-based split\n",
    "    train_df = df[df['timestamp'] < '2023-04-01']\n",
    "    test_df = df[df['timestamp'] >= '2023-04-01']\n",
    "\n",
    "    reader = Reader(rating_scale=(0, 2))\n",
    "    train_data = Dataset.load_from_df(train_df[['user_id', 'liked_user_id', 'like_type']], reader)\n",
    "    test_data = Dataset.load_from_df(test_df[['user_id', 'liked_user_id', 'like_type']], reader)\n",
    "\n",
    "    trainset = train_data.build_full_trainset()\n",
    "    testset = test_data.build_full_trainset().build_testset()\n",
    "\n",
    "    models = {\n",
    "        \"SVD\": SVD(),\n",
    "        \"KNNBasic\": KNNBasic(),\n",
    "        \"NMF\": NMF()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        \n",
    "        precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1)\n",
    "\n",
    "        avg_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "        avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "        \n",
    "        results[name] = {\"precision\": avg_precision, \"recall\": avg_recall}\n",
    "        \n",
    "        print(f\"  Precision@10: {avg_precision:.4f}\")\n",
    "        print(f\"  Recall@10: {avg_recall:.4f}\")\n",
    "        print()\n",
    "\n",
    "    print(\"--- Final Results ---\")\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{name}: Precision@10={metrics['precision']:.4f}, Recall@10={metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVD...\n",
      "  Precision@10: 0.9888\n",
      "  Recall@10: 0.1295\n",
      "\n",
      "Evaluating KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  Precision@10: 0.9875\n",
      "  Recall@10: 0.1378\n",
      "\n",
      "Evaluating NMF...\n",
      "  Precision@10: 0.9985\n",
      "  Recall@10: 0.1138\n",
      "\n",
      "--- Final Results ---\n",
      "SVD: Precision@10=0.9888, Recall@10=0.1295\n",
      "KNNBasic: Precision@10=0.9875, Recall@10=0.1378\n",
      "NMF: Precision@10=0.9985, Recall@10=0.1138\n"
     ]
    }
   ],
   "source": [
    "run_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== ADDITIONAL IMPROVEMENTS TO TRY ===\n",
    "1. FEATURE ENGINEERING:\n",
    "   - Add user demographics (age, gender, location)\n",
    "   - Add item features (category, price, popularity)\n",
    "   - Time-based features (season, day of week)\n",
    "\n",
    "2. MATRIX FACTORIZATION VARIANTS:\n",
    "   - Non-negative Matrix Factorization (NMF)\n",
    "   - Probabilistic Matrix Factorization (PMF)\n",
    "   - Bayesian Personalized Ranking (BPR)\n",
    "\n",
    "3. DEEP LEARNING ALTERNATIVES:\n",
    "   - Autoencoders for collaborative filtering\n",
    "   - Variational Autoencoders (VAE)\n",
    "   - Neural Matrix Factorization\n",
    "   - Graph Neural Networks (GNNs)\n",
    "\n",
    "4. EXTERNAL LIBRARIES:\n",
    "   - Install 'implicit' library: pip install implicit\n",
    "   - Install 'lightfm' library: pip install lightfm\n",
    "   - Try Microsoft Recommenders toolkit\n",
    "   - PyTorch Geometric for graph-based methods\n",
    "\n",
    "5. EVALUATION IMPROVEMENTS:\n",
    "   - Use ranking metrics (NDCG, MAP)\n",
    "   - Cross-validation with temporal splits\n",
    "   - A/B testing framework\n",
    "\n",
    "6. PYTORCH OPTIMIZATIONS:\n",
    "   - Use mixed precision training (torch.cuda.amp)\n",
    "   - Implement learning rate scheduling\n",
    "   - Add gradient clipping for stability\n",
    "   - Use DataParallel for multi-GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
